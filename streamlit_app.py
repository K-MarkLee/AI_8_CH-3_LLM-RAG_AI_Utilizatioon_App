import streamlit as st
import logging
import os
import json
import time
import io

from datetime import datetime
from gtts import gTTS
import base64
import tempfile
import requests
from urllib.parse import urljoin

from gtts import gTTS
import streamlit.components.v1 as components
import base64
from collections import deque
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    raise EnvironmentError("Error: OpenAI_API_KEY is not set. Please configure it in your environment.")
os.environ["OpenAI_API_KEY"] = api_key

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


<<<<<<< HEAD

db_path = "./food_db/"
# ê¸°ë³¸ ì„¤ì •
model = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
recipes_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
retriever = recipes_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})


# í”„ë¡¬í”„íŠ¸ ë¡œë“œ í•¨ìˆ˜
def load_prompts(path, system_files):
    system_message = []
    for txt in system_files:
        try:
            with open(os.path.join(path, txt), "r", encoding="UTF-8") as f:
                content = f.read().replace("\\n", "\n")
                system_message.append(("system", content))
                
        except FileNotFoundError:
            logger.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ '{txt}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ '{txt}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ '{txt}' ì½ê¸° ì‹¤íŒ¨: {e}")
            st.error(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ '{txt}' ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()
            
    system_message.append(("user", "data : {data}\\n\\nQuestion: {question}"))
    return system_message


# í”„ë¡¬í”„íŠ¸ ê²½ë¡œ
prompt_path = "./Prompts/"
system_message = load_prompts(prompt_path, ["Require_decide.txt", "Food_recipe.txt", "Food_recommend.txt"])
prompt = ChatPromptTemplate.from_messages(system_message)




# JSON íŒŒì¼ ì„¤ì •
json_path = "./log/"
json_file = None  # ì „ì—­ ë³€ìˆ˜ë¡œ ì´ˆê¸°í™”


# JSON íŒŒì¼ ìƒì„± í•¨ìˆ˜
def create_json_file(base_dir=json_path, prefix="output_log"):
    global json_file  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©
    if json_file is None:  # íŒŒì¼ì´ ì—†ì„ ë•Œë§Œ ìƒì„±
        if not os.path.exists(base_dir):
            os.makedirs(base_dir)
        timestamp = time.strftime("%Y%m%d_%H")
        json_file = os.path.join(base_dir, f"{prefix}_{timestamp}.json")
    return json_file



# JSON íŒŒì¼ì— ê¸°ë¡ ì €ì¥
# JSON íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def append_to_json(user_input, assistant_response):
    """
    ìœ ì € ì…ë ¥ê³¼ ëª¨ë¸ ì‘ë‹µì„ JSON íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    file_path = create_json_file()  # í•­ìƒ ë™ì¼í•œ íŒŒì¼ì„ ì°¸ì¡°
    try:
        # ê¸°ì¡´ JSON ë°ì´í„° ë¡œë“œ
        if os.path.exists(file_path):
            with open(file_path, "r", encoding="utf-8") as f:
                existing_data = json.load(f)
        else:
            existing_data = []
        
        # ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
        new_record = {
            "user_input": user_input,
            "assistant_response": assistant_response
        }
        existing_data.append(new_record)

        # ë°ì´í„°ë¥¼ JSON íŒŒì¼ì— ê¸°ë¡
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logger.error(f"JSON ì €ì¥ ì‹¤íŒ¨: {e}")
        
        
        
# TTS ìŒì„± ì¬ìƒ í•¨ìˆ˜
def play_audio(text):
    """
    gTTSë¥¼ ì´ìš©í•´ ìŒì„±ì„ ìƒì„±í•˜ê³  Streamlitì—ì„œ ë°”ë¡œ ì¬ìƒ.
    """
    tts = gTTS(text=text, lang="ko")
    # ìŒì„± íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
    audio_buffer = io.BytesIO()
    tts.write_to_fp(audio_buffer)
    audio_buffer.seek(0)
    
    # base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ Streamlitì—ì„œ ì¬ìƒ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
    audio_base64 = base64.b64encode(audio_buffer.read()).decode()
    audio_html = f"""
        <audio autoplay controls>
            <source src="data:audio/mpeg;base64,{audio_base64}" type="audio/mpeg">
        </audio>
    """
    components.html(audio_html, height=80)  # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì‚½ì…
        
        

# Debug PassThrough ì„¤ì •
class DebugPassThrough(RunnablePassthrough):
    def invoke(self, *args, **kwargs):
        output = super().invoke(*args, **kwargs)
        return output

# ContextToText: ë°ì´í„° ìœ ì‹¤ ë°©ì§€
class ContextToText(RunnablePassthrough):
    def invoke(self, inputs, config=None, **kwargs):
        # inputs["data"] = inputs["data"][-3:]  # ë§ˆì§€ë§‰ 3ê°œì˜ ë°ì´í„°ë§Œ í¬í•¨

        # ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
        return {"data": inputs["data"], "question": inputs["question"]}


# ë­ì²´ì¸ ì—°ê²°
rag_chain_divide = {
    "data": retriever,
    "question": DebugPassThrough(),
} | DebugPassThrough() | ContextToText() | prompt | model

        
        

# Streamlit UI êµ¬ì„±
def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = deque(maxlen=3)
    if "response" not in st.session_state:
        st.session_state.response = ""

=======
def autoplay_audio(audio_content, autoplay=True):
    """ìŒì„± ì¬ìƒì„ ìœ„í•œ HTML ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
    b64 = base64.b64encode(audio_content).decode()
    md = f"""
        <audio {' autoplay' if autoplay else ''} controls>
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """
    return st.markdown(md, unsafe_allow_html=True)

def text_to_speech(text, lang='ko'):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
            tts = gTTS(text=text, lang=lang)
            tts.save(fp.name)
            with open(fp.name, 'rb') as audio_file:
                audio_bytes = audio_file.read()
            os.unlink(fp.name)
            return audio_bytes
    except Exception as e:
        logger.error(f"ìŒì„± ë³€í™˜ ì˜¤ë¥˜: {e}")
        return None

def fetch_github_files(repo_path, folder_path):
    """GitHub ì €ì¥ì†Œì—ì„œ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        # GitHub API URL êµ¬ì„±
        api_url = f"https://api.github.com/repos/{repo_path}/contents/{folder_path}"
        response = requests.get(api_url)
        response.raise_for_status()
        
        files = []
        for item in response.json():
            if item['type'] == 'file' and item['name'].endswith('.json'):
                files.append({
                    'name': item['name'],
                    'download_url': item['download_url']
                })
        return True, files
    except Exception as e:
        logger.error(f"GitHub íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return False, str(e)

def download_github_file(file_url):
    """GitHubì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        response = requests.get(file_url)
        response.raise_for_status()
        return response.content
    except Exception as e:
        logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def process_github_files(repo_path="Dawol2205/chatbot_test", folder_path="food_DB"):
    """GitHub ì €ì¥ì†Œì—ì„œ JSON íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    success, files = fetch_github_files(repo_path, folder_path)
    if not success:
        return False, f"íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {files}"

    documents = []
    for file in files:
        try:
            content = download_github_file(file['download_url'])
            if content:
                # JSON íŒŒì‹±
                data = json.loads(content)
                
                # Document ê°ì²´ ìƒì„±
                doc = Document(
                    page_content=json.dumps(data, ensure_ascii=False, indent=2),
                    metadata={"source": file['name']}
                )
                documents.append(doc)
                
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({file['name']}): {e}")
            continue

    if not documents:
        return False, "ì²˜ë¦¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    return True, documents

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "initialized" not in st.session_state:
        st.session_state.initialized = True
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant", 
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ìš”ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì–´ë–¤ ìš”ë¦¬ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                "audio": None
            }
        ]
    if "vectorstore" not in st.session_state:
        st.session_state.vectorstore = None
    if "custom_prompt" not in st.session_state:
        st.session_state.custom_prompt = """
ì•„ë˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}
ë‹µë³€: ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤.
"""
    if "voice_enabled" not in st.session_state:
        st.session_state.voice_enabled = True
>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6


<<<<<<< HEAD
=======
def get_text_chunks(documents):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100
    )
    return text_splitter.split_documents(documents)

def create_vector_store(documents):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    return FAISS.from_documents(documents=documents, embedding=embeddings)

def save_vectorstore_local(vectorstore, directory=VECTOR_PATH):
    """ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œì»¬ì— ì €ì¥"""
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_path = os.path.join(directory, f"vectorstore_{timestamp}.pkl")
        
        with open(file_path, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        return True, file_path
    except Exception as e:
        logger.error(f"ë¡œì»¬ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False, str(e)

def load_vectorstore_local(file_path):
    """ë¡œì»¬ì—ì„œ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    try:
        with open(file_path, 'rb') as f:
            vectorstore = pickle.load(f)
        return True, vectorstore
    except Exception as e:
        logger.error(f"ë¡œì»¬ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False, str(e)

def get_conversation_chain(vectorstore, openai_api_key, custom_prompt):
    """ëŒ€í™” ì²´ì¸ ìƒì„±"""
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4o-mini', temperature=0)
    
    PROMPT = PromptTemplate(
        template=custom_prompt,
        input_variables=["context", "question"]
    )
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_type='mmr', verbose=True),
        memory=ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        ),
        combine_docs_chain_kwargs={"prompt": PROMPT},
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )

    return conversation_chain
>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6

def main():
    try:
        st.set_page_config(page_title="ìš”ë¦¬ ì „ë¬¸ê°€ ì±—ë´‡", page_icon="ğŸ³", layout="wide")
        st.title("ìš”ë¦¬ ì „ë¬¸ê°€ ì±—ë´‡")
        st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ìš”ë¦¬ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        initialize_session_state()
        create_json_file()
        
        
        # ì‚¬ì´ë“œë°” êµ¬ì„±
        with st.sidebar:
            st.header("ì„¤ì •")
            
<<<<<<< HEAD
            # TTS on/off ì„¤ì •
            tts_enabled = st.checkbox("TTS (í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜)", value=False)
=======
            # ìŒì„± ì¶œë ¥ í† ê¸€
            st.session_state.voice_enabled = st.toggle("ìŒì„± ì¶œë ¥ í™œì„±í™”", value=st.session_state.voice_enabled)
            
            # API í‚¤ ì…ë ¥
            openai_api_key = st.text_input("OpenAI API Key", type="password")
            if not openai_api_key:
                st.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")
>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6

            # ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", key="reset_button"):
                st.session_state.chat_history.clear()  # chat_history ì´ˆê¸°í™”
                st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")  # ë©”ì‹œì§€ ì¶œë ¥

<<<<<<< HEAD
        

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥
            user_input = {"role": "user", "content": query}
            st.session_state.chat_history.append(user_input)

            with st.chat_message("user"):
                st.write(query)

=======
            # GitHub íŒŒì¼ ì²˜ë¦¬ ì„¹ì…˜
            st.header("GitHub íŒŒì¼ ì²˜ë¦¬")
            if st.button("GitHubì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°"):
                if not validate_api_key(openai_api_key):
                    st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    st.stop()

                try:
                    with st.spinner("GitHubì—ì„œ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
                        success, result = process_github_files()
                        
                        if success:
                            # ë¬¸ì„œ ì²­í¬ ìƒì„±
                            chunks = get_text_chunks(result)
                            
                            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                            vectorstore = create_vector_store(chunks)
                            
                            # ì„¸ì…˜ì— ì €ì¥
                            st.session_state.vectorstore = vectorstore
                            st.session_state.conversation = get_conversation_chain(
                                vectorstore, 
                                openai_api_key,
                                st.session_state.custom_prompt
                            )
                            st.success("GitHub íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
                        else:
                            st.error(f"GitHub íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {result}")

                except Exception as e:
                    st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            # ë²¡í„° íŒŒì¼ ì €ì¥ ë²„íŠ¼
            save_button = st.button("ë²¡í„° ì €ì¥")

            # ë²¡í„° íŒŒì¼ ë¡œë“œ ì„¹ì…˜
            st.header("ë²¡í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°")
            vector_files = []
            if os.path.exists(VECTOR_PATH):
                vector_files = [f for f in os.listdir(VECTOR_PATH) if f.endswith('.pkl')]
            
            if vector_files:
                selected_file = st.selectbox("ì €ì¥ëœ ë²¡í„° íŒŒì¼ ì„ íƒ", vector_files)
                load_button = st.button("ë²¡í„° ë¶ˆëŸ¬ì˜¤ê¸°")
            else:
                st.info("ì €ì¥ëœ ë²¡í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ë²¡í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        if vector_files and load_button and selected_file:
            if not validate_api_key(openai_api_key):
                st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    file_path = os.path.join(VECTOR_PATH, selected_file)
                    success, result = load_vectorstore_local(file_path)
                    
                    if success:
                        st.session_state.vectorstore = result
                        st.session_state.conversation = get_conversation_chain(
                            result, 
                            openai_api_key,
                            st.session_state.custom_prompt
                        )
                        st.success("ë²¡í„° ì €ì¥ì†Œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                    else:
                        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {result}")
                        
            except Exception as e:
                st.error(f"ë²¡í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.error(f"ë¡œì»¬ ë¡œë“œ ì˜¤ë¥˜: {e}")

        # ë²¡í„° ì €ì¥ì†Œ ë¡œì»¬ ì €ì¥
        if save_button:
            if not st.session_state.vectorstore:
                st.error("ì €ì¥í•  ë²¡í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ ì €ì¥í•˜ëŠ” ì¤‘..."):
                    success, result = save_vectorstore_local(st.session_state.vectorstore)
                    if success:
                        st.success(f"ë²¡í„° ì €ì¥ì†Œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤! (ê²½ë¡œ: {result})")
                    else:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {result}")

            except Exception as e:
                st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                logger.error(f"ì €ì¥ ì˜¤ë¥˜: {e}")

        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        chat_container = st.container()
        with chat_container:
            for i, message in enumerate(st.session_state.messages):
                with st.chat_message(message["role"]):
                    st.write(message["content"])
                    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì— ëŒ€í•´ ìŒì„± ì»¨íŠ¸ë¡¤ ì¶”ê°€
                    if message["role"] == "assistant" and st.session_state.voice_enabled:
                        if message.get("audio") is None and message["content"]:
                            # ìŒì„±ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì€ ê²½ìš° ìƒì„±
                            audio_bytes = text_to_speech(message["content"])
                            if audio_bytes:
                                message["audio"] = audio_bytes

                        if message.get("audio"):
                            # ìŒì„± ì»¨íŠ¸ë¡¤ í‘œì‹œ
                            cols = st.columns([1, 4])
                            with cols[0]:
                                if st.button("ğŸ”Š ì¬ìƒ", key=f"play_message_{i}"):
                                    autoplay_audio(message["audio"])
                            with cols[1]:
                                # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ í‘œì‹œ (ì»¨íŠ¸ë¡¤ í¬í•¨)
                                autoplay_audio(message["audio"], autoplay=False)

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": query, "audio": None})
            
            with st.chat_message("user"):
                st.write(query)

            if not st.session_state.conversation:
                response = "ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ê±°ë‚˜ ì €ì¥ëœ ë²¡í„°ë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”."
                st.warning(response)
                
                if st.session_state.voice_enabled:
                    audio_bytes = text_to_speech(response)
                else:
                    audio_bytes = None
                    
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "audio": audio_bytes
                })
                
                if audio_bytes:
                    autoplay_audio(audio_bytes)
                
                st.stop()

>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        # ëª¨ë¸ í˜¸ì¶œ ë° ì‘ë‹µ ì²˜ë¦¬
                        model_input = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.chat_history])
                        response = rag_chain_divide.invoke(model_input)
                        assistant_response = {"role": "assistant", "content": response.content}
                        st.session_state.chat_history.append(assistant_response)

<<<<<<< HEAD
                        # JSONì— ê¸°ë¡
                        append_to_json(query, response.content)
                        
                        st.write(response.content)
                        
                        if tts_enabled:
                            play_audio(response.content)
=======
                        st.write(response)

                        # ìŒì„± ì¶œë ¥ ì²˜ë¦¬
                        if st.session_state.voice_enabled:
                            audio_bytes = text_to_speech(response)
                            if audio_bytes:
                                autoplay_audio(audio_bytes)
                        else:
                            audio_bytes = None

                        if source_documents:
                            with st.expander("ì°¸ê³  ë¬¸ì„œ"):
                                for i, doc in enumerate(source_documents[:3], 1):
                                    st.markdown(f"**ì°¸ê³  {i}:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')}")
                                    st.markdown(f"```\n{doc.page_content[:200]}...\n```")

                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": response,
                            "audio": audio_bytes
                        })
>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6

                    except Exception as e:
                        error_message = f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                        error_data = {"role": "assistant", "content": error_message}
                        st.session_state.chat_history.append(error_data)
                        append_to_json(error_data)
                        st.error(error_message)
<<<<<<< HEAD

=======
                        
                        if st.session_state.voice_enabled:
                            audio_bytes = text_to_speech(error_message)
                        else:
                            audio_bytes = None
                            
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_message,
                            "audio": audio_bytes
                        })
                        
                        if audio_bytes:
                            autoplay_audio(audio_bytes)
                            
                        logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
>>>>>>> e1873d44ad42954c5a41b0a685ba2b4de61b82e6

    except Exception as e:
        logger.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
