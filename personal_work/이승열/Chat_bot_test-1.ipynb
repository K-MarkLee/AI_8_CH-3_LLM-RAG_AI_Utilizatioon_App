{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import faiss\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "from uuid import uuid4\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OpenAI_API_KEY\"] = os.getenv(\"GPT_API\")\n",
    "\n",
    "model = ChatOpenAI(model =\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = \"food_recipe/\"\n",
    "\n",
    "# # 병합된 데이터를 저장할 리스트\n",
    "# merged_data = []\n",
    "\n",
    "# # 폴더 내 모든 JSON 파일 읽기\n",
    "# for file_name in os.listdir(folder_path):\n",
    "#     if file_name.endswith(\".json\"):  # JSON 파일만 처리\n",
    "#         file_path = os.path.join(folder_path, file_name)\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             try:\n",
    "#                 # JSON 데이터 불러오기\n",
    "#                 data = json.load(file)\n",
    "#                 merged_data.append(data)  # 병합 리스트에 추가\n",
    "#                 print(f\"Added data from {file_name}\")\n",
    "#             except json.JSONDecodeError as e:\n",
    "#                 print(f\"Error decoding {file_name}: {e}\")\n",
    "\n",
    "# # 병합된 데이터를 하나의 JSON 파일로 저장\n",
    "# output_path = os.path.join(folder_path, \"final_recipes_data.json\")\n",
    "# with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "#     json.dump(merged_data, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# print(f\"병합된 JSON 데이터가 {output_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"food_recipe/food_recipes_1-68.json\",'r',encoding='utf-8') as file:\n",
    "#     data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_recipe = [\n",
    "#     Document(page_content=str(recipe), metadata={\"요리명\": recipe[\"요리명\"],\"요리재료\" : recipe[\"요리재료\"], \"기본정보\" : recipe[\"기본정보\"], \"조리순서\" : recipe[\"조리순서\"]})\n",
    "#     for recipe in data\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index  = faiss.IndexFlatL2(len(embeddings.embed_query(\"레시피\")))\n",
    "\n",
    "# recipe_store = FAISS(\n",
    "#     embedding_function=embeddings,\n",
    "#     index=index,\n",
    "#     docstore=InMemoryDocstore(),\n",
    "#     index_to_docstore_id={}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuids = [str(uuid4()) for _ in range(len(document_recipe))]\n",
    "\n",
    "# recipe_store.add_documents(documents=document_recipe, ids = uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_store.save_local(\"./food_db\")\n",
    "recipes = FAISS.load_local(\"./food_db.\" ,embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = recipes.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"너는 주어진 데이터로만 답변을 할 수 있어.\"),\n",
    "#     (\"system\", \"너는 요리의 전문가야.\"),\n",
    "    \n",
    "    \n",
    "#     (\"system\", \"질문에 답변할 때는 항상 데이터를 세밀히 학습하고 정확한 답변을 생성해야 해.\"),\n",
    "#     (\"system\", \"만약 데이터 안에 유저의 질문이 없다면, 양해를 구하고 관련 데이터를 제공할 수 없음을 알리도록 해.\"),\n",
    "#     (\"system\", \"질문에 계산이 필요한 경우, 데이터를 기반으로 정확하게 계산하여 결과를 제공해야 합니다.\"),\n",
    "#     (\"system\", \"질문에 대한 답변을 생성 하기전에 검증을 마친 후에 생성해줘.\"),\n",
    "#     (\"system\", \"부족한 부분이 있다고 생각하면, 다른 데이터를 참조해줘\"),\n",
    "\n",
    "    \n",
    "#     (\"system\", \"다음은 답변 형식의 예시야: \\n\"\n",
    "#                \"user: 미역국을 만들고 싶어.\\n\"\n",
    "#                \"ai: 미역국의 재료는 ~입니다.\\n\"\n",
    "#                \"ai: 미역국을 만드는 순서는 다음과 같습니다:\\n\"\n",
    "#                \"ai: 첫 번째 ~~~, 두 번째 ~~~입니다.\\n\"),\n",
    "    \n",
    "    \n",
    "#     (\"system\", \"또 다른 예시를 들어줄게:\\n\"\n",
    "#                \"user: 내가 만들려고 하는 미역국의 칼로리는 얼마야?\\n\"\n",
    "#                \"ai: 미역국의 칼로리는 1인분당 ~kcal입니다. 이 레시피는 ~인분 기준이므로, 총 칼로리는 ~kcal입니다.\\n\"),\n",
    "    \n",
    "    \n",
    "#     (\"system\", \"추가 예시:\\n\"\n",
    "#                \"user: 5인분의 레시피로 수정해줘.\\n\"\n",
    "#                \"ai: 현재 미역국 레시피는 ~인분 기준입니다. 5인분으로 수정된 재료는 다음과 같습니다:\\n\"\n",
    "#                \"ai: ~~~.\\n\"\n",
    "#                \"이때도 순서를 전부 알려줘\"),\n",
    "    \n",
    "    \n",
    "#     (\"system\", \"추가 예시:\\n\"\n",
    "#                \"user: 된장찌개 끓이는법을 알려줘.\\n\"\n",
    "#                \"ai: 된장찌개는 재료에 따라 나뉩니다. 현재 ~ 한 된장찌개 레시피가 있습니다 어떤 된장찌개 레시피를원하십니까?:\\n\"\n",
    "#                ),\n",
    "    \n",
    "    \n",
    "#     (\"user\", \"다음과 같은 데이터를 학습해:\\n{data}\"),\n",
    "#     (\"user\", \"그리고 질문에 답해:\\n{question}\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 위치 설정\n",
    "path = \"Prompts/\"\n",
    "\n",
    "\n",
    "system_files = [\"Require_decide.txt\",\"Food_recipe.txt\",\"Food_recommend.txt\"]\n",
    "\n",
    "\n",
    "system_message = []\n",
    "for txt in system_files :\n",
    "    with open(os.path.join(path, txt),\"r\", encoding=\"UTF-8\") as f:\n",
    "       \n",
    "        content = f.read().replace(\"\\\\n\", \"\\n\")\n",
    "        system_message.append((\"system\", content))\n",
    "\n",
    "\n",
    "system_message.append((\"user\", \"context : {context}\\\\n\\\\nQuestion: {question}\"))\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(system_message)\n",
    "prompt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_prompt = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    \n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args,**kwargs)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config = None, **kwargs):\n",
    "        return {\"data\": inputs[\"data\"], \"question\": inputs[\"question\"]}\n",
    "    \n",
    "    \n",
    "rag_chain_divide = {\n",
    "    \"data\" : retriever,\n",
    "    \"question\" : DebugPassThrough()\n",
    "\n",
    "\n",
    "# contextual_prompt에 기능을 분리시키는 프롬프트 입력 (~라면 a를 반환, ~라면 b를 반환)\n",
    "} | DebugPassThrough() | ContextToText()| contextual_prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 히스토리를 저장할 공간\n",
    "chat_history = deque(maxlen = 10)\n",
    "log = []\n",
    "timestamp = time.time()\n",
    "output_file = f\"log/output_log_{timestamp}.json\"\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    \n",
    "    query = input(\"질문을 입력해 주세요 (break 입력시 종료됩니다) : \")\n",
    "    \n",
    "    \n",
    "    if query.lower() == \"break\":\n",
    "        # 결과를 JSON 파일로 저장\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(log, f, ensure_ascii=False, indent=4)\n",
    "        break\n",
    "    \n",
    "    # 히스토리에 사용자 입력 추가\n",
    "    chat_history.append({\"role\": \"user\", \"content\" : query})\n",
    "    \n",
    "    \n",
    "    #모델의 입력 구성\n",
    "    model_input = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in chat_history])\n",
    "\n",
    "\n",
    "    #응답 생성\n",
    "    response = rag_chain_divide.invoke(model_input)\n",
    "    \n",
    "    \n",
    "    # 히스토리에 모델의 응답 추가\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "    \n",
    "    \n",
    "    #저장\n",
    "    record = {\n",
    "        \"질문\" : query,\n",
    "        \"답변\" : response.content,\n",
    "        \"기록\" : list(chat_history)\n",
    "    }\n",
    "    log.append(record)\n",
    "    \n",
    "\n",
    "    print(\"Question : \", query)\n",
    "    \n",
    "    print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
