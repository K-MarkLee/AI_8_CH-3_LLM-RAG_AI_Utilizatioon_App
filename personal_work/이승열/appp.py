import os
import json
import time
import logging
from collections import deque
from uuid import uuid4
from datetime import datetime
from dotenv import load_dotenv

import streamlit as st

from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

######################################################################
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise EnvironmentError("Error: OpenAI_API_KEY is not set. Please configure it in your environment.")
os.environ["OpenAI_API_KEY"] = api_key

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



######################################################################



# ëª¨ë¸ ë° ë°ì´í„° ì„¤ì •
model = ChatOpenAI(model="gpt-4o-mini")
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
VECTOR_PATH = "food_db/"
recipes = FAISS.load_local(VECTOR_PATH, embeddings, allow_dangerous_deserialization=True)

# ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
retriever = recipes.as_retriever(search_type="similarity", search_kwargs={"k": 5})


######################################################################

# í”„ë¡¬í”„íŠ¸ ë¡œë“œ í•¨ìˆ˜
def load_prompts(path, system_files):
    system_message = []
    for txt in system_files:
        try:
            with open(os.path.join(path, txt), "r", encoding="UTF-8") as f:
                content = f.read().replace("\\n", "\n")
                system_message.append(("system", content))
        except FileNotFoundError:
            print(f"Warning: Prompt file '{txt}' not found.")
        except Exception as e:
            print(f"Error loading prompt '{txt}': {e}")
    system_message.append(("user", "data : {data}\\n\\nQuestion: {question}"))
    return system_message

system_message = load_prompts("Prompts/", ["Require_decide.txt", "Food_recipe.txt", "Food_recommend.txt"])
prompt = ChatPromptTemplate.from_messages(system_message)
print(prompt)


######################################################################



# ë­ì²´ì¸ ì—°ê²°
class DebugPassThrough(RunnablePassthrough):
    def invoke(self, *args, **kwargs):
        output = super().invoke(*args, **kwargs)
        return output

class ContextToText(RunnablePassthrough):
    def invoke(self, inputs, config=None, **kwargs):
        inputs["data"] = inputs["data"][-3:]  # ë§ˆì§€ë§‰ 3ê°œì˜ ë°ì´í„°ë§Œ í¬í•¨
        return {"data": inputs["data"], "question": inputs["question"]}

rag_chain_divide = {
    "data": retriever,
    "question": DebugPassThrough(),
} | DebugPassThrough() | ContextToText() | prompt | model




# ëŒ€í™” íˆìŠ¤í† ë¦¬ ë° JSON ì €ì¥ ì„¤ì •
chat_history = deque(maxlen=10)
log = []



def create_json_file(base_dir="personal_work/ì´ìŠ¹ì—´/log", prefix="output_log"):
    if not os.path.exists(base_dir):
        os.makedirs(base_dir)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    return os.path.join(base_dir, f"{prefix}_{timestamp}.json")


output_file = create_json_file()



def save_to_json(file_path, data):
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)



def get_response(user_input):
    chat_history.append({"role": "user", "content": user_input})
    model_input = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history])
    response = rag_chain_divide.invoke(model_input)
    chat_history.append({"role": "assistant", "content": response.content})
    return response.content


######################################################################
# Streamlit UI
def main():
    st.set_page_config(
        page_title="ìš”ë¦¬ ë„ìš°ë¯¸",
        page_icon="ğŸ³",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("ìš”ë¦¬ ë„ìš°ë¯¸ ğŸ³")
    st.subheader("ìš”ë¦¬ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!")

    # ëŒ€í™” ì¸í„°í˜ì´ìŠ¤
    chat_container = st.container()
    with chat_container:
        for message in chat_history:
            with st.chat_message(message["role"]):
                st.write(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        with st.chat_message("user"):
            st.write(query)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    response = get_response(query)
                    st.write(response)
                    log.append({"ì§ˆë¬¸": query, "ë‹µë³€": response, "ê¸°ë¡": list(chat_history)})
                except Exception as e:
                    st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ë¡œê·¸ ì €ì¥ ì˜µì…˜
    if st.button("ë¡œê·¸ ì €ì¥"):
        save_to_json(output_file, log)
        st.success("ë¡œê·¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
